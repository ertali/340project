{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "OxwkOdL2Mpbc",
        "outputId": "da8533b6-df11-456a-adfe-764372fbeef2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7bca1a94-9f95-4431-9522-6015f6a77209\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7bca1a94-9f95-4431-9522-6015f6a77209\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving cosine_features_per_article.csv to cosine_features_per_article.csv\n"
          ]
        }
      ],
      "source": [
        "'''Import all files:\n",
        "- Embeddings of the front pages ('better_cleaned_embeddings.csv')\n",
        "- Embeddings of the articles ('articles_with_embeddings')\n",
        "- NLI data ('nli_analysis_all_articles.csv')\n",
        "- Cosine ('cosine_features_per_article.csv')\n",
        "- Data for each stock ('SPY.csv', 'VT.csv', etc)\n",
        "'''\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Nk5EYZdOOIJQ",
        "outputId": "042654aa-5afb-46b2-e1fb-d4fac1fe386f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (3.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (2.32.3)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.0.9)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (3.13.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.15.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2025.1.31)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras->keras-tuner) (4.13.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ],
      "source": [
        "#Installs\n",
        "!pip install keras-tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TtzDQVcTL8oA"
      },
      "outputs": [],
      "source": [
        "#Imports\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras\n",
        "import tensorflow.keras.datasets\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "import tensorflow.keras.optimizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import ast\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "import keras_tuner as kt\n",
        "import os\n",
        "import tensorflow.keras.backend as K\n",
        "from sklearn.utils.class_weight import compute_class_weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygoV7LlxOGw3",
        "outputId": "8027f4e4-8baa-44c8-9b4d-e70725a08b64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 3.5123 - mae: 1.2182 - val_loss: 1.0362 - val_mae: 0.6803\n",
            "Epoch 2/150\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3605 - mae: 0.7530 - val_loss: 1.0400 - val_mae: 0.6862\n",
            "Epoch 3/150\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2407 - mae: 0.7122 - val_loss: 1.1031 - val_mae: 0.7115\n",
            "Epoch 4/150\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1597 - mae: 0.7075 - val_loss: 1.0908 - val_mae: 0.7095\n",
            "Epoch 5/150\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1138 - mae: 0.6989 - val_loss: 1.1142 - val_mae: 0.7203\n",
            "Epoch 6/150\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.9058 - mae: 0.6714 - val_loss: 1.2327 - val_mae: 0.7653\n",
            "Epoch 7/150\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 1.4509 - mae: 0.7314 - val_loss: 1.0560 - val_mae: 0.6900\n",
            "Epoch 8/150\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 1.1053 - mae: 0.6884 - val_loss: 1.0770 - val_mae: 0.6967\n",
            "Epoch 9/150\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1.3786 - mae: 0.6880 - val_loss: 1.0924 - val_mae: 0.7296\n",
            "Epoch 10/150\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.9889 - mae: 0.6750 - val_loss: 1.1290 - val_mae: 0.7234\n",
            "Epoch 11/150\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.2126 - mae: 0.6831 - val_loss: 1.2036 - val_mae: 0.7569\n",
            "Epoch 12/150\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0092 - mae: 0.6694 - val_loss: 1.0558 - val_mae: 0.6929\n",
            "Epoch 13/150\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.9888 - mae: 0.6850 - val_loss: 1.0874 - val_mae: 0.7029\n",
            "Epoch 14/150\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1166 - mae: 0.7088 - val_loss: 1.1144 - val_mae: 0.7085\n",
            "Epoch 15/150\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.2405 - mae: 0.7321 - val_loss: 1.0761 - val_mae: 0.6938\n",
            "Epoch 16/150\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1.5759 - mae: 0.7125 - val_loss: 1.0940 - val_mae: 0.6999\n",
            "Epoch 16: early stopping\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1003 - mae: 0.6865 \n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "   predicted_change  actual_change\n",
            "0          0.082230       0.415608\n",
            "1          0.106464      -1.945760\n",
            "2          0.093488       0.291244\n",
            "3          0.092371       0.050915\n",
            "4          0.038965       1.435311\n",
            "R²: -0.009372830390930176\n",
            "MSE: 0.8493629097938538\n",
            "MAE: 0.6582750678062439\n"
          ]
        }
      ],
      "source": [
        "#Neural network for embeddings on front page\n",
        "#Regression\n",
        "\n",
        "#Import embeddings, convert to matrix\n",
        "embeddings = pd.read_csv(\"better_cleaned_embeddings.csv\")\n",
        "embeddings['Embedding'] = embeddings['Embedding'].apply(ast.literal_eval)\n",
        "embedding_matrix = np.vstack(embeddings['Embedding'].values)\n",
        "\n",
        "X = np.array(embedding_matrix).astype('float32')\n",
        "y = np.array(embeddings['SPY'].to_numpy()).astype('float32').reshape(-1, 1)\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Normalize inputs\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define model\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_shape=(X.shape[1],)))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(1, activation='linear'))  #Linear activation function\n",
        "\n",
        "# Compile and train\n",
        "model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), metrics=['mae'])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True, verbose=1)\n",
        "\n",
        "model.fit(\n",
        "    X_train_scaled, y_train,\n",
        "    batch_size=64,\n",
        "    epochs=150,\n",
        "    verbose=1,\n",
        "    validation_data=(X_val_scaled, y_val),\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "# Evaluate on validation set\n",
        "val_loss, val_mae = model.evaluate(X_val_scaled, y_val)\n",
        "\n",
        "# Predictions on test set\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Save predictions alongside actuals\n",
        "results = pd.DataFrame({\n",
        "    'predicted_change': y_pred.flatten(),\n",
        "    'actual_change': y_test.flatten()\n",
        "})\n",
        "\n",
        "print(results.head())\n",
        "\n",
        "r2 = r2_score(results['actual_change'], results['predicted_change'])\n",
        "print(\"R²:\", r2_score(y_test, y_pred))\n",
        "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
        "print(\"MAE:\", mean_absolute_error(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzD3lSdyOKMI",
        "outputId": "87952902-7b4a-4e21-8531-ba4c73a0c2e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.5264 - loss: 0.8283 - val_accuracy: 0.5496 - val_loss: 0.6927\n",
            "Epoch 2/150\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5874 - loss: 0.6847 - val_accuracy: 0.5305 - val_loss: 0.7001\n",
            "Epoch 3/150\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6288 - loss: 0.6498 - val_accuracy: 0.4695 - val_loss: 0.7398\n",
            "Epoch 4/150\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6725 - loss: 0.6122 - val_accuracy: 0.5534 - val_loss: 0.6906\n",
            "Epoch 5/150\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6914 - loss: 0.5730 - val_accuracy: 0.5573 - val_loss: 0.7593\n",
            "Epoch 6/150\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7294 - loss: 0.5175 - val_accuracy: 0.5115 - val_loss: 0.8098\n",
            "Epoch 7/150\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7493 - loss: 0.4730 - val_accuracy: 0.5496 - val_loss: 0.7752\n",
            "Epoch 8/150\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7550 - loss: 0.4649 - val_accuracy: 0.5611 - val_loss: 1.0443\n",
            "Epoch 9/150\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8312 - loss: 0.4032 - val_accuracy: 0.5649 - val_loss: 1.0605\n",
            "Epoch 10/150\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8280 - loss: 0.3870 - val_accuracy: 0.5115 - val_loss: 1.4342\n",
            "Epoch 11/150\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8525 - loss: 0.3288 - val_accuracy: 0.5496 - val_loss: 1.4107\n",
            "Epoch 12/150\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8736 - loss: 0.3075 - val_accuracy: 0.5420 - val_loss: 1.4344\n",
            "Epoch 13/150\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8761 - loss: 0.3432 - val_accuracy: 0.5649 - val_loss: 1.3150\n",
            "Epoch 14/150\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8926 - loss: 0.2872 - val_accuracy: 0.5191 - val_loss: 1.5482\n",
            "Epoch 15/150\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9124 - loss: 0.2311 - val_accuracy: 0.5420 - val_loss: 1.8104\n",
            "Epoch 16/150\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9006 - loss: 0.2658 - val_accuracy: 0.5153 - val_loss: 2.1056\n",
            "Epoch 17/150\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9193 - loss: 0.2007 - val_accuracy: 0.5191 - val_loss: 1.8813\n",
            "Epoch 18/150\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9185 - loss: 0.2082 - val_accuracy: 0.5573 - val_loss: 1.8454\n",
            "Epoch 19/150\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9044 - loss: 0.2344 - val_accuracy: 0.5611 - val_loss: 1.6672\n",
            "Epoch 19: early stopping\n",
            "Restoring model weights from the end of the best epoch: 4.\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5932 - loss: 0.6864 \n",
            "Validation Accuracy: 0.5534350872039795\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "   predicted_label  actual_label\n",
            "0                0             1\n",
            "1                1             0\n",
            "2                0             1\n",
            "3                1             1\n",
            "4                0             1\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.44      0.42       110\n",
            "           1       0.57      0.53      0.55       152\n",
            "\n",
            "    accuracy                           0.49       262\n",
            "   macro avg       0.48      0.48      0.48       262\n",
            "weighted avg       0.50      0.49      0.49       262\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Neural network for embeddings on the full front pages\n",
        "#classification\n",
        "\n",
        "X = np.array(embedding_matrix).astype('float32')\n",
        "#binary output\n",
        "y = (embeddings['SPY'].to_numpy() > 0).astype('int32').reshape(-1, 1)\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_shape=(X.shape[1],)))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(1, activation='sigmoid'))  # Binary output\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True, verbose=1)\n",
        "\n",
        "model.fit(\n",
        "    X_train_scaled, y_train,\n",
        "    batch_size=64,\n",
        "    epochs=150,\n",
        "    verbose=1,\n",
        "    validation_data=(X_val_scaled, y_val),\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "val_loss, val_accuracy = model.evaluate(X_val_scaled, y_val)\n",
        "print(\"Validation Accuracy:\", val_accuracy)\n",
        "\n",
        "y_pred_probs = model.predict(X_test_scaled)\n",
        "y_pred_labels = (y_pred_probs > 0.5).astype('int32')\n",
        "\n",
        "results = pd.DataFrame({\n",
        "    'predicted_label': y_pred_labels.flatten(),\n",
        "    'actual_label': y_test.flatten()\n",
        "})\n",
        "\n",
        "print(results.head())\n",
        "\n",
        "print(classification_report(y_test, y_pred_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1hnjQkeRDgL",
        "outputId": "02abc885-da4b-4a55-8013-2b8b08a704a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 90 Complete [00h 00m 25s]\n",
            "val_mae: 0.5124397277832031\n",
            "\n",
            "Best val_mae So Far: 0.4393603801727295\n",
            "Total elapsed time: 00h 14m 51s\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.3513 - mae: 0.5221 \n",
            "Model 1: Test MAE = 0.5267, Loss (MSE) = 0.3536\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2900 - mae: 0.4888  \n",
            "Model 2: Test MAE = 0.4975, Loss (MSE) = 0.3019\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2985 - mae: 0.4885  \n",
            "Model 3: Test MAE = 0.4930, Loss (MSE) = 0.3024\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3238 - mae: 0.5223  \n",
            "Model 4: Test MAE = 0.5069, Loss (MSE) = 0.3077\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3069 - mae: 0.5067  \n",
            "Model 5: Test MAE = 0.5014, Loss (MSE) = 0.3024\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3113 - mae: 0.5091  \n",
            "Model 6: Test MAE = 0.4961, Loss (MSE) = 0.2976\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3238 - mae: 0.5170  \n",
            "Model 7: Test MAE = 0.5086, Loss (MSE) = 0.3146\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3152 - mae: 0.5029\n",
            "Model 8: Test MAE = 0.5061, Loss (MSE) = 0.3223\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2967 - mae: 0.4997  \n",
            "Model 9: Test MAE = 0.5012, Loss (MSE) = 0.2978\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3184 - mae: 0.5012  \n",
            "Model 10: Test MAE = 0.5073, Loss (MSE) = 0.3233\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3183 - mae: 0.4945  \n",
            "Model 11: Test MAE = 0.4934, Loss (MSE) = 0.3120\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2805 - mae: 0.4811 \n",
            "Model 12: Test MAE = 0.4766, Loss (MSE) = 0.2717\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.4187 - mae: 0.5572 \n",
            "Model 13: Test MAE = 0.5508, Loss (MSE) = 0.4083\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.3863 - mae: 0.5450  \n",
            "Model 14: Test MAE = 0.5408, Loss (MSE) = 0.3820\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.3094 - mae: 0.4989\n",
            "Model 15: Test MAE = 0.4950, Loss (MSE) = 0.3079\n"
          ]
        }
      ],
      "source": [
        "#Hyperparameter tuning for embeddings on the full front pages\n",
        "#regression\n",
        "\n",
        "y_regression = y.astype('float32')\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train_scaled, X_temp, y_train, y_temp = train_test_split(X_scaled, y_regression, test_size=0.2, random_state=42)\n",
        "X_val_scaled, X_test_scaled, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(\n",
        "        hp.Int('units_input', min_value=64, max_value=256, step=64),\n",
        "        activation=hp.Choice('activation_input', ['relu', 'tanh']),\n",
        "        input_shape=(X.shape[1],)\n",
        "    ))\n",
        "\n",
        "    for i in range(hp.Int('num_layers', 1, 3)):\n",
        "        model.add(Dense(\n",
        "            units=hp.Int(f'units_{i}', min_value=64, max_value=512, step=64),\n",
        "            activation=hp.Choice(f'activation_{i}', ['relu', 'tanh'])\n",
        "        ))\n",
        "        if hp.Boolean(f'dropout_{i}'):\n",
        "            model.add(Dropout(rate=hp.Float(f'dropout_rate_{i}', min_value=0.1, max_value=0.5, step=0.1)))\n",
        "\n",
        "    model.add(Dense(1, activation='linear'))\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(\n",
        "            learning_rate=hp.Float('lr', 1e-5, 1e-3, sampling='log')),\n",
        "        loss='mean_squared_error',\n",
        "        metrics=['mae']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "tuner = kt.Hyperband(\n",
        "    build_model,\n",
        "    objective='val_mae',\n",
        "    max_epochs=30,\n",
        "    factor=3,\n",
        "    directory='hyperband_dir',\n",
        "    project_name='tlt_direction_regression'\n",
        ")\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "tuner.search(\n",
        "    X_train_scaled, y_train,\n",
        "    epochs=50,\n",
        "    validation_data=(X_val_scaled, y_val),\n",
        "    callbacks=[early_stopping],\n",
        "    batch_size=64\n",
        ")\n",
        "\n",
        "best_models = tuner.get_best_models(num_models=15)\n",
        "\n",
        "for idx, model in enumerate(best_models):\n",
        "    test_loss, test_mae = model.evaluate(X_test_scaled, y_test, verbose=1)\n",
        "    print(f\"Model {idx+1}: Test MAE = {test_mae:.4f}, Loss (MSE) = {test_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFgSh4CYcq9L",
        "outputId": "1d417f7b-1cc8-489a-b456-42be6d63ffc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step\n",
            "Model 1: R² = -0.4516\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step\n",
            "Model 2: R² = -0.2393\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n",
            "Model 3: R² = -0.2415\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Model 4: R² = -0.2631\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Model 5: R² = -0.2414\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Model 6: R² = -0.2216\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "Model 7: R² = -0.2916\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Model 8: R² = -0.3231\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "Model 9: R² = -0.2228\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "Model 10: R² = -0.3272\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "Model 11: R² = -0.2807\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Model 12: R² = -0.1154\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Model 13: R² = -0.6765\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "Model 14: R² = -0.5682\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "Model 15: R² = -0.2642\n"
          ]
        }
      ],
      "source": [
        "for idx, model in enumerate(best_models):\n",
        "    y_pred = model.predict(X_test_scaled).flatten()\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    print(f\"Model {idx+1}: R² = {r2:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "C2vXwyi6RGIb",
        "outputId": "72fbf2d3-b7e1-4578-9d24-005a783446c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 90 Complete [00h 00m 13s]\n",
            "val_accuracy: 0.5419847369194031\n",
            "\n",
            "Best val_accuracy So Far: 0.6030534505844116\n",
            "Total elapsed time: 00h 15m 44s\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "Model 1: Accuracy = 0.5038\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.37      0.39       110\n",
            "           1       0.57      0.60      0.58       152\n",
            "\n",
            "    accuracy                           0.50       262\n",
            "   macro avg       0.49      0.49      0.49       262\n",
            "weighted avg       0.50      0.50      0.50       262\n",
            "\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Model 2: Accuracy = 0.5229\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.42      0.38      0.40       110\n",
            "           1       0.58      0.62      0.60       152\n",
            "\n",
            "    accuracy                           0.52       262\n",
            "   macro avg       0.50      0.50      0.50       262\n",
            "weighted avg       0.52      0.52      0.52       262\n",
            "\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Model 3: Accuracy = 0.5420\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.40      0.42       110\n",
            "           1       0.60      0.64      0.62       152\n",
            "\n",
            "    accuracy                           0.54       262\n",
            "   macro avg       0.52      0.52      0.52       262\n",
            "weighted avg       0.54      0.54      0.54       262\n",
            "\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Model 4: Accuracy = 0.5038\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.42      0.45      0.43       110\n",
            "           1       0.58      0.54      0.56       152\n",
            "\n",
            "    accuracy                           0.50       262\n",
            "   macro avg       0.50      0.50      0.50       262\n",
            "weighted avg       0.51      0.50      0.51       262\n",
            "\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "Model 5: Accuracy = 0.5038\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.39      0.34      0.36       110\n",
            "           1       0.57      0.62      0.59       152\n",
            "\n",
            "    accuracy                           0.50       262\n",
            "   macro avg       0.48      0.48      0.48       262\n",
            "weighted avg       0.49      0.50      0.50       262\n",
            "\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "Model 6: Accuracy = 0.5305\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.45      0.44       110\n",
            "           1       0.60      0.59      0.59       152\n",
            "\n",
            "    accuracy                           0.53       262\n",
            "   macro avg       0.52      0.52      0.52       262\n",
            "weighted avg       0.53      0.53      0.53       262\n",
            "\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Model 7: Accuracy = 0.5076\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.41      0.39      0.40       110\n",
            "           1       0.57      0.59      0.58       152\n",
            "\n",
            "    accuracy                           0.51       262\n",
            "   macro avg       0.49      0.49      0.49       262\n",
            "weighted avg       0.50      0.51      0.51       262\n",
            "\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Model 8: Accuracy = 0.5267\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.53      0.48       110\n",
            "           1       0.61      0.53      0.56       152\n",
            "\n",
            "    accuracy                           0.53       262\n",
            "   macro avg       0.53      0.53      0.52       262\n",
            "weighted avg       0.54      0.53      0.53       262\n",
            "\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "Model 9: Accuracy = 0.5076\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.39      0.30      0.34       110\n",
            "           1       0.56      0.66      0.61       152\n",
            "\n",
            "    accuracy                           0.51       262\n",
            "   macro avg       0.48      0.48      0.47       262\n",
            "weighted avg       0.49      0.51      0.49       262\n",
            "\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Model 10: Accuracy = 0.5420\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.53      0.49       110\n",
            "           1       0.62      0.55      0.58       152\n",
            "\n",
            "    accuracy                           0.54       262\n",
            "   macro avg       0.54      0.54      0.54       262\n",
            "weighted avg       0.55      0.54      0.54       262\n",
            "\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Model 11: Accuracy = 0.4962\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.41      0.46      0.44       110\n",
            "           1       0.57      0.52      0.54       152\n",
            "\n",
            "    accuracy                           0.50       262\n",
            "   macro avg       0.49      0.49      0.49       262\n",
            "weighted avg       0.50      0.50      0.50       262\n",
            "\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "Model 12: Accuracy = 0.5611\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.23      0.30       110\n",
            "           1       0.59      0.80      0.68       152\n",
            "\n",
            "    accuracy                           0.56       262\n",
            "   macro avg       0.52      0.51      0.49       262\n",
            "weighted avg       0.53      0.56      0.52       262\n",
            "\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "Model 13: Accuracy = 0.5382\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.34      0.38       110\n",
            "           1       0.59      0.68      0.63       152\n",
            "\n",
            "    accuracy                           0.54       262\n",
            "   macro avg       0.51      0.51      0.51       262\n",
            "weighted avg       0.52      0.54      0.53       262\n",
            "\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "Model 14: Accuracy = 0.5000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.39      0.33      0.35       110\n",
            "           1       0.56      0.62      0.59       152\n",
            "\n",
            "    accuracy                           0.50       262\n",
            "   macro avg       0.47      0.48      0.47       262\n",
            "weighted avg       0.49      0.50      0.49       262\n",
            "\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Model 15: Accuracy = 0.5115\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.31      0.35       110\n",
            "           1       0.57      0.66      0.61       152\n",
            "\n",
            "    accuracy                           0.51       262\n",
            "   macro avg       0.48      0.48      0.48       262\n",
            "weighted avg       0.50      0.51      0.50       262\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Hyperparameter tuning for embeddings on the full front pages\n",
        "#classification\n",
        "\n",
        "y_binary = (y > 0).astype('int32')\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train_scaled, X_temp, y_train, y_temp = train_test_split(X_scaled, y_binary, test_size=0.2, random_state=42)\n",
        "X_val_scaled, X_test_scaled, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(\n",
        "        hp.Int('units_input', min_value=64, max_value=256, step=64),\n",
        "        activation=hp.Choice('activation_input', ['relu', 'tanh']),\n",
        "        input_shape=(X.shape[1],)\n",
        "    ))\n",
        "\n",
        "    for i in range(hp.Int('num_layers', 1, 3)):\n",
        "        model.add(Dense(\n",
        "            units=hp.Int(f'units_{i}', min_value=64, max_value=512, step=64),\n",
        "            activation=hp.Choice(f'activation_{i}', ['relu', 'tanh'])\n",
        "        ))\n",
        "        if hp.Boolean(f'dropout_{i}'):\n",
        "            model.add(Dropout(rate=hp.Float(f'dropout_rate_{i}', min_value=0.1, max_value=0.5, step=0.1)))\n",
        "\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(\n",
        "            learning_rate=hp.Float('lr', 1e-5, 1e-3, sampling='log')),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "tuner = kt.Hyperband(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_epochs=30,\n",
        "    factor=3,\n",
        "    directory='hyperband_dir',\n",
        "    project_name='tlt_direction_classification'\n",
        ")\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "tuner.search(\n",
        "    X_train_scaled, y_train,\n",
        "    epochs=50,\n",
        "    validation_data=(X_val_scaled, y_val),\n",
        "    callbacks=[early_stopping],\n",
        "    batch_size=64\n",
        ")\n",
        "\n",
        "best_models = tuner.get_best_models(num_models=15)\n",
        "\n",
        "for idx, model in enumerate(best_models):\n",
        "    y_pred_probs = model.predict(X_test_scaled)\n",
        "    y_pred = (y_pred_probs > 0.5).astype('int32')\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Model {idx+1}: Accuracy = {acc:.4f}\")\n",
        "    print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvS5g3VkRIb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5a5d78f-a88e-4f4f-a04c-5ba39a6ad254"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 2.8843 - mae: 1.1075 - val_loss: 1.1905 - val_mae: 0.7197\n",
            "Epoch 2/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.5175 - mae: 0.7920 - val_loss: 1.2131 - val_mae: 0.7209\n",
            "Epoch 3/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.4605 - mae: 0.7852 - val_loss: 1.2289 - val_mae: 0.7321\n",
            "Epoch 4/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.4897 - mae: 0.7828 - val_loss: 1.2210 - val_mae: 0.7286\n",
            "Epoch 5/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.6125 - mae: 0.7863 - val_loss: 1.2678 - val_mae: 0.7377\n",
            "Epoch 6/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.5217 - mae: 0.7758 - val_loss: 1.2001 - val_mae: 0.7232\n",
            "Epoch 7/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.2523 - mae: 0.7607 - val_loss: 1.5394 - val_mae: 0.7674\n",
            "Epoch 8/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.3568 - mae: 0.7443 - val_loss: 1.2208 - val_mae: 0.7270\n",
            "Epoch 9/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 1.5513 - mae: 0.7908 - val_loss: 1.1960 - val_mae: 0.7208\n",
            "Epoch 10/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 1.4739 - mae: 0.7716 - val_loss: 1.2079 - val_mae: 0.7243\n",
            "Epoch 11/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1.5884 - mae: 0.7586 - val_loss: 1.1907 - val_mae: 0.7196\n",
            "Epoch 12/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.5514 - mae: 0.7837 - val_loss: 1.1946 - val_mae: 0.7194\n",
            "Epoch 13/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.6721 - mae: 0.7909 - val_loss: 1.2032 - val_mae: 0.7211\n",
            "Epoch 14/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.7205 - mae: 0.8120 - val_loss: 1.1897 - val_mae: 0.7211\n",
            "Epoch 15/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.7707 - mae: 0.8100 - val_loss: 1.1982 - val_mae: 0.7203\n",
            "Epoch 16/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5781 - mae: 0.7733 - val_loss: 1.1925 - val_mae: 0.7186\n",
            "Epoch 17/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.5055 - mae: 0.7840 - val_loss: 1.1897 - val_mae: 0.7189\n",
            "Epoch 18/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.4892 - mae: 0.7830 - val_loss: 1.1915 - val_mae: 0.7186\n",
            "Epoch 19/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.5654 - mae: 0.7769 - val_loss: 1.1903 - val_mae: 0.7188\n",
            "Epoch 20/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.5153 - mae: 0.7773 - val_loss: 1.1935 - val_mae: 0.7189\n",
            "Epoch 21/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.5395 - mae: 0.7673 - val_loss: 1.1921 - val_mae: 0.7186\n",
            "Epoch 22/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.6169 - mae: 0.7995 - val_loss: 1.1919 - val_mae: 0.7186\n",
            "Epoch 23/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.4607 - mae: 0.7513 - val_loss: 1.1905 - val_mae: 0.7187\n",
            "Epoch 24/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.4222 - mae: 0.7708 - val_loss: 1.1920 - val_mae: 0.7186\n",
            "Epoch 25/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.6209 - mae: 0.7858 - val_loss: 1.1927 - val_mae: 0.7187\n",
            "Epoch 26/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.5236 - mae: 0.7878 - val_loss: 1.1902 - val_mae: 0.7188\n",
            "Epoch 27/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.6618 - mae: 0.7957 - val_loss: 1.1907 - val_mae: 0.7186\n",
            "Epoch 28/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.6115 - mae: 0.7852 - val_loss: 1.1913 - val_mae: 0.7186\n",
            "Epoch 29/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 1.3367 - mae: 0.7628 - val_loss: 1.1909 - val_mae: 0.7186\n",
            "Epoch 29: early stopping\n",
            "Restoring model weights from the end of the best epoch: 14.\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.8802 - mae: 0.6761\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "   predicted_change  actual_change\n",
            "0         -0.021804       0.173300\n",
            "1         -0.021804       0.131039\n",
            "2         -0.021804       0.009519\n",
            "3         -0.021804       0.065154\n",
            "4         -0.021804      -1.608434\n",
            "R²: -0.012429475784301758\n",
            "MSE: 1.1785101890563965\n",
            "MAE: 0.7351405024528503\n"
          ]
        }
      ],
      "source": [
        "#Neural network for embeddings on the articles\n",
        "#regression\n",
        "\n",
        "split_articles = pd.read_csv(\"articles_with_embeddings.csv\")\n",
        "split_articles['Date'] = pd.to_datetime(split_articles['Date']).dt.date\n",
        "\n",
        "tickers = [\"SPY\", \"QQQ\", \"DIA\", \"TLT\", \"IEF\", \"VT\", \"IWM\"]\n",
        "\n",
        "for ticker in tickers:\n",
        "    df_stock = pd.read_csv(f\"{ticker}.csv\")\n",
        "\n",
        "    df_stock['timestamp'] = pd.to_datetime(df_stock['timestamp']) + pd.Timedelta(days=-1)\n",
        "    df_stock['timestamp'] = df_stock['timestamp'].dt.date\n",
        "\n",
        "    if df_stock['timestamp'].max() < min(split_articles['Date']):\n",
        "        print(f\"Skipping {ticker} — no overlapping dates.\")\n",
        "        continue\n",
        "\n",
        "    df_change = df_stock[['timestamp', 'prev_day_percent_change']].rename(columns={\n",
        "        'timestamp': 'Date',\n",
        "        'prev_day_percent_change': ticker\n",
        "    })\n",
        "    split_articles = pd.merge(split_articles, df_change, on='Date', how='left')\n",
        "\n",
        "split_articles = split_articles.dropna(subset=tickers, how='all')\n",
        "\n",
        "split_articles['Embedding'] = split_articles['Embedding'].apply(ast.literal_eval)\n",
        "embedding_matrix = np.vstack(split_articles['Embedding'].values)\n",
        "\n",
        "X = np.array(embedding_matrix).astype('float32')\n",
        "y = np.array(split_articles['SPY'].to_numpy()).astype('float32').reshape(-1, 1)\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_shape=(X.shape[1],)))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), metrics=['mae'])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True, verbose=1)\n",
        "\n",
        "model.fit(\n",
        "    X_train_scaled, y_train,\n",
        "    batch_size=64,\n",
        "    epochs=150,\n",
        "    verbose=1,\n",
        "    validation_data=(X_val_scaled, y_val),\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "val_loss, val_mae = model.evaluate(X_val_scaled, y_val)\n",
        "\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "results = pd.DataFrame({\n",
        "    'predicted_change': y_pred.flatten(),\n",
        "    'actual_change': y_test.flatten()\n",
        "})\n",
        "\n",
        "print(results.head())\n",
        "\n",
        "r2 = r2_score(results['actual_change'], results['predicted_change'])\n",
        "print(\"R²:\", r2_score(y_test, y_pred))\n",
        "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
        "print(\"MAE:\", mean_absolute_error(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3iijPcaRKZw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ccf4095-5200-4502-a266-701a2c9ef4b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.5103 - loss: 0.8296 - val_accuracy: 0.5368 - val_loss: 0.6971\n",
            "Epoch 2/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5377 - loss: 0.6918 - val_accuracy: 0.5368 - val_loss: 0.6887\n",
            "Epoch 3/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5494 - loss: 0.6857 - val_accuracy: 0.5629 - val_loss: 0.6963\n",
            "Epoch 4/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5788 - loss: 0.6796 - val_accuracy: 0.4656 - val_loss: 0.7167\n",
            "Epoch 5/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5766 - loss: 0.6772 - val_accuracy: 0.5487 - val_loss: 0.7448\n",
            "Epoch 6/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5904 - loss: 0.6501 - val_accuracy: 0.5416 - val_loss: 0.7496\n",
            "Epoch 7/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5962 - loss: 0.6403 - val_accuracy: 0.5297 - val_loss: 0.7863\n",
            "Epoch 8/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6300 - loss: 0.6107 - val_accuracy: 0.5226 - val_loss: 0.7665\n",
            "Epoch 9/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6444 - loss: 0.6120 - val_accuracy: 0.4917 - val_loss: 0.7477\n",
            "Epoch 10/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6479 - loss: 0.6052 - val_accuracy: 0.5083 - val_loss: 0.7360\n",
            "Epoch 11/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6584 - loss: 0.5921 - val_accuracy: 0.5202 - val_loss: 0.8235\n",
            "Epoch 12/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6593 - loss: 0.5646 - val_accuracy: 0.4964 - val_loss: 0.8807\n",
            "Epoch 13/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6678 - loss: 0.5797 - val_accuracy: 0.5226 - val_loss: 1.2884\n",
            "Epoch 14/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6809 - loss: 0.5553 - val_accuracy: 0.4893 - val_loss: 0.7466\n",
            "Epoch 15/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6569 - loss: 0.5711 - val_accuracy: 0.5012 - val_loss: 0.8732\n",
            "Epoch 16/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6624 - loss: 0.5486 - val_accuracy: 0.5012 - val_loss: 1.0858\n",
            "Epoch 17/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6969 - loss: 0.5226 - val_accuracy: 0.4941 - val_loss: 0.9948\n",
            "Epoch 17: early stopping\n",
            "Restoring model weights from the end of the best epoch: 2.\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5193 - loss: 0.6901 \n",
            "Validation Accuracy: 0.5368170738220215\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "   predicted_label  actual_label\n",
            "0                1             1\n",
            "1                1             1\n",
            "2                1             1\n",
            "3                1             1\n",
            "4                1             0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.09      0.15       178\n",
            "           1       0.57      0.90      0.70       243\n",
            "\n",
            "    accuracy                           0.56       421\n",
            "   macro avg       0.49      0.50      0.42       421\n",
            "weighted avg       0.50      0.56      0.47       421\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Neural network for embeddings on the articles\n",
        "#classification\n",
        "\n",
        "X = np.array(embedding_matrix).astype('float32')\n",
        "#binary output\n",
        "y = (split_articles['SPY'].to_numpy() > 0).astype('int32').reshape(-1, 1)\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_shape=(X.shape[1],)))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(1, activation='sigmoid'))  # Binary output\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True, verbose=1)\n",
        "\n",
        "model.fit(\n",
        "    X_train_scaled, y_train,\n",
        "    batch_size=64,\n",
        "    epochs=150,\n",
        "    verbose=1,\n",
        "    validation_data=(X_val_scaled, y_val),\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "val_loss, val_accuracy = model.evaluate(X_val_scaled, y_val)\n",
        "print(\"Validation Accuracy:\", val_accuracy)\n",
        "\n",
        "y_pred_probs = model.predict(X_test_scaled)\n",
        "y_pred_labels = (y_pred_probs > 0.5).astype('int32')\n",
        "\n",
        "results = pd.DataFrame({\n",
        "    'predicted_label': y_pred_labels.flatten(),\n",
        "    'actual_label': y_test.flatten()\n",
        "})\n",
        "\n",
        "print(results.head())\n",
        "\n",
        "print(classification_report(y_test, y_pred_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5I9yY3yRWBo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73159109-1c1a-4243-9f9f-ee078bcd4cd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 2.1354 - mae: 0.9556 - val_loss: 1.3574 - val_mae: 0.7522\n",
            "Epoch 2/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 1.5984 - mae: 0.8076 - val_loss: 1.3616 - val_mae: 0.7544\n",
            "Epoch 3/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 1.6339 - mae: 0.8110 - val_loss: 1.3542 - val_mae: 0.7548\n",
            "Epoch 4/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 1.4322 - mae: 0.7763 - val_loss: 1.3599 - val_mae: 0.7543\n",
            "Epoch 5/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.5084 - mae: 0.7794 - val_loss: 1.3315 - val_mae: 0.7544\n",
            "Epoch 6/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1.7887 - mae: 0.8035 - val_loss: 1.3634 - val_mae: 0.7543\n",
            "Epoch 7/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.7537 - mae: 0.8201 - val_loss: 1.3643 - val_mae: 0.7557\n",
            "Epoch 8/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.6711 - mae: 0.8093 - val_loss: 1.3457 - val_mae: 0.7657\n",
            "Epoch 9/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 1.4785 - mae: 0.7875 - val_loss: 1.3560 - val_mae: 0.7527\n",
            "Epoch 10/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.6013 - mae: 0.7976 - val_loss: 1.3615 - val_mae: 0.7557\n",
            "Epoch 11/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1.7094 - mae: 0.8184 - val_loss: 1.3440 - val_mae: 0.7511\n",
            "Epoch 12/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 1.5572 - mae: 0.7808 - val_loss: 1.3624 - val_mae: 0.7536\n",
            "Epoch 13/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 1.6214 - mae: 0.7989 - val_loss: 1.3730 - val_mae: 0.7573\n",
            "Epoch 14/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 1.6891 - mae: 0.8181 - val_loss: 1.3698 - val_mae: 0.7563\n",
            "Epoch 15/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1.6143 - mae: 0.7994 - val_loss: 1.3687 - val_mae: 0.7593\n",
            "Epoch 16/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.5248 - mae: 0.8020 - val_loss: 1.4070 - val_mae: 0.7846\n",
            "Epoch 17/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.5767 - mae: 0.7884 - val_loss: 1.3678 - val_mae: 0.7549\n",
            "Epoch 18/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.6534 - mae: 0.8148 - val_loss: 1.3653 - val_mae: 0.7541\n",
            "Epoch 19/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.4674 - mae: 0.7770 - val_loss: 1.3609 - val_mae: 0.7535\n",
            "Epoch 20/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.5224 - mae: 0.7940 - val_loss: 1.3670 - val_mae: 0.7544\n",
            "Epoch 20: early stopping\n",
            "Restoring model weights from the end of the best epoch: 5.\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1992 - mae: 0.7366 \n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "   predicted_change  actual_change\n",
            "0          0.090635       0.359842\n",
            "1          0.101507       0.071179\n",
            "2          0.096754       0.446725\n",
            "3          0.109503       0.771484\n",
            "4          0.103040      -1.920218\n",
            "R²: 0.0449374714187627\n",
            "MSE: 1.5148220700430706\n",
            "MAE: 0.7862845074793242\n"
          ]
        }
      ],
      "source": [
        "#Neural network for cosine/MNLI\n",
        "#regression\n",
        "\n",
        "cosine = pd.read_csv(\"cosine_features_per_article.csv\")\n",
        "nli = pd.read_csv(\"nli_analysis_all_articles.csv\")\n",
        "\n",
        "merged = pd.merge(cosine, nli, on=\"Article_Index\")\n",
        "spy = pd.read_csv(\"SPY.csv\")\n",
        "vt = pd.read_csv(\"VT.csv\")\n",
        "spy['timestamp'] = pd.to_datetime(spy['timestamp'])\n",
        "merged['Date'] = pd.to_datetime(merged['Date'])\n",
        "merged_with_market = pd.merge(\n",
        "    merged,\n",
        "    spy[['timestamp', 'prev_day_percent_change']],\n",
        "    left_on='Date',\n",
        "    right_on='timestamp',\n",
        "    how='inner'\n",
        ")\n",
        "merged_with_market = merged_with_market.drop(columns=['timestamp'])\n",
        "merged_with_market.rename(columns={'prev_day_percent_change': 'market_change'}, inplace=True)\n",
        "merged_with_market.head()\n",
        "drop_cols = ['Article_Index', 'Date', 'Article_Text'] + \\\n",
        "            [col for col in merged_with_market.columns if 'Sentence' in col or 'Error' in col]\n",
        "X = merged_with_market.drop(columns=drop_cols)\n",
        "X = X.drop(columns='market_change')\n",
        "y = merged_with_market['market_change']\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_shape=(X.shape[1],)))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "model.compile(\n",
        "    loss='mean_squared_error',\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "    metrics=['mae']\n",
        ")\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True, verbose=1)\n",
        "\n",
        "model.fit(\n",
        "    X_train_scaled, y_train,\n",
        "    batch_size=64,\n",
        "    epochs=150,\n",
        "    verbose=1,\n",
        "    validation_data=(X_val_scaled, y_val),\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "val_loss, val_mae = model.evaluate(X_val_scaled, y_val)\n",
        "\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "results = pd.DataFrame({\n",
        "    'predicted_change': y_pred.flatten(),\n",
        "    'actual_change': np.array(y_test).flatten()\n",
        "})\n",
        "\n",
        "print(results.head())\n",
        "\n",
        "r2 = r2_score(results['actual_change'], results['predicted_change'])\n",
        "print(\"R²:\", r2_score(y_test, y_pred))\n",
        "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
        "print(\"MAE:\", mean_absolute_error(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KpZU2R4ARZYV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c620c664-820d-474d-a9b1-70a2de7df1e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5242 - loss: 0.7172 - val_accuracy: 0.5469 - val_loss: 0.6889\n",
            "Epoch 2/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5618 - loss: 0.6867 - val_accuracy: 0.5423 - val_loss: 0.6889\n",
            "Epoch 3/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5687 - loss: 0.6869 - val_accuracy: 0.5355 - val_loss: 0.6896\n",
            "Epoch 4/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5576 - loss: 0.6869 - val_accuracy: 0.5469 - val_loss: 0.6923\n",
            "Epoch 5/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5699 - loss: 0.6897 - val_accuracy: 0.5652 - val_loss: 0.6869\n",
            "Epoch 6/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5562 - loss: 0.6862 - val_accuracy: 0.5492 - val_loss: 0.6895\n",
            "Epoch 7/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5734 - loss: 0.6825 - val_accuracy: 0.5446 - val_loss: 0.6883\n",
            "Epoch 8/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5718 - loss: 0.6848 - val_accuracy: 0.5469 - val_loss: 0.6875\n",
            "Epoch 9/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5553 - loss: 0.6864 - val_accuracy: 0.5515 - val_loss: 0.6877\n",
            "Epoch 10/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5659 - loss: 0.6840 - val_accuracy: 0.5469 - val_loss: 0.6884\n",
            "Epoch 11/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5725 - loss: 0.6827 - val_accuracy: 0.5492 - val_loss: 0.6887\n",
            "Epoch 12/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5711 - loss: 0.6842 - val_accuracy: 0.5492 - val_loss: 0.6870\n",
            "Epoch 13/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5745 - loss: 0.6836 - val_accuracy: 0.5469 - val_loss: 0.6893\n",
            "Epoch 14/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5451 - loss: 0.6904 - val_accuracy: 0.5469 - val_loss: 0.6893\n",
            "Epoch 15/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5736 - loss: 0.6823 - val_accuracy: 0.5446 - val_loss: 0.6868\n",
            "Epoch 16/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5580 - loss: 0.6881 - val_accuracy: 0.5492 - val_loss: 0.6864\n",
            "Epoch 17/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5562 - loss: 0.6865 - val_accuracy: 0.5492 - val_loss: 0.6873\n",
            "Epoch 18/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5651 - loss: 0.6850 - val_accuracy: 0.5492 - val_loss: 0.6881\n",
            "Epoch 19/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5670 - loss: 0.6853 - val_accuracy: 0.5469 - val_loss: 0.6883\n",
            "Epoch 20/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5518 - loss: 0.6896 - val_accuracy: 0.5492 - val_loss: 0.6881\n",
            "Epoch 21/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5680 - loss: 0.6841 - val_accuracy: 0.5492 - val_loss: 0.6868\n",
            "Epoch 22/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5688 - loss: 0.6843 - val_accuracy: 0.5469 - val_loss: 0.6881\n",
            "Epoch 23/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5588 - loss: 0.6873 - val_accuracy: 0.5492 - val_loss: 0.6874\n",
            "Epoch 24/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5688 - loss: 0.6834 - val_accuracy: 0.5492 - val_loss: 0.6865\n",
            "Epoch 25/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5652 - loss: 0.6853 - val_accuracy: 0.5492 - val_loss: 0.6872\n",
            "Epoch 26/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5499 - loss: 0.6868 - val_accuracy: 0.5492 - val_loss: 0.6866\n",
            "Epoch 27/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5612 - loss: 0.6844 - val_accuracy: 0.5469 - val_loss: 0.6888\n",
            "Epoch 28/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5489 - loss: 0.6886 - val_accuracy: 0.5446 - val_loss: 0.6887\n",
            "Epoch 29/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5700 - loss: 0.6836 - val_accuracy: 0.5538 - val_loss: 0.6861\n",
            "Epoch 30/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5513 - loss: 0.6875 - val_accuracy: 0.5469 - val_loss: 0.6869\n",
            "Epoch 31/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5612 - loss: 0.6846 - val_accuracy: 0.5469 - val_loss: 0.6910\n",
            "Epoch 32/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5724 - loss: 0.6821 - val_accuracy: 0.5515 - val_loss: 0.6871\n",
            "Epoch 33/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5576 - loss: 0.6930 - val_accuracy: 0.5492 - val_loss: 0.6881\n",
            "Epoch 34/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5578 - loss: 0.6891 - val_accuracy: 0.5492 - val_loss: 0.6889\n",
            "Epoch 35/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5699 - loss: 0.6835 - val_accuracy: 0.5492 - val_loss: 0.6869\n",
            "Epoch 36/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5654 - loss: 0.6840 - val_accuracy: 0.5469 - val_loss: 0.6877\n",
            "Epoch 37/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5587 - loss: 0.6847 - val_accuracy: 0.5469 - val_loss: 0.6896\n",
            "Epoch 38/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5584 - loss: 0.6859 - val_accuracy: 0.5469 - val_loss: 0.6906\n",
            "Epoch 39/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5642 - loss: 0.6839 - val_accuracy: 0.5469 - val_loss: 0.6904\n",
            "Epoch 40/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5674 - loss: 0.6844 - val_accuracy: 0.5469 - val_loss: 0.6895\n",
            "Epoch 41/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5585 - loss: 0.6853 - val_accuracy: 0.5469 - val_loss: 0.6882\n",
            "Epoch 42/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5675 - loss: 0.6820 - val_accuracy: 0.5469 - val_loss: 0.6878\n",
            "Epoch 43/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5533 - loss: 0.6872 - val_accuracy: 0.5446 - val_loss: 0.6927\n",
            "Epoch 44/150\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5719 - loss: 0.6894 - val_accuracy: 0.5423 - val_loss: 0.6955\n",
            "Epoch 44: early stopping\n",
            "Restoring model weights from the end of the best epoch: 29.\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5894 - loss: 0.6786 \n",
            "Validation Accuracy: 0.5537757277488708\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "   predicted_label  actual_label\n",
            "0                1             1\n",
            "1                1             1\n",
            "2                1             1\n",
            "3                1             1\n",
            "4                1             0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.43      0.02      0.03       194\n",
            "           1       0.56      0.98      0.71       243\n",
            "\n",
            "    accuracy                           0.55       437\n",
            "   macro avg       0.49      0.50      0.37       437\n",
            "weighted avg       0.50      0.55      0.41       437\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Neural network for cosine/MNLI\n",
        "#classification\n",
        "\n",
        "y = (merged_with_market['market_change'].to_numpy() > 0).astype('int32').reshape(-1, 1)\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_shape=(X.shape[1],)))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True, verbose=1)\n",
        "\n",
        "model.fit(\n",
        "    X_train_scaled, y_train,\n",
        "    batch_size=64,\n",
        "    epochs=150,\n",
        "    verbose=1,\n",
        "    validation_data=(X_val_scaled, y_val),\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "val_loss, val_accuracy = model.evaluate(X_val_scaled, y_val)\n",
        "print(\"Validation Accuracy:\", val_accuracy)\n",
        "\n",
        "y_pred_probs = model.predict(X_test_scaled)\n",
        "y_pred_labels = (y_pred_probs > 0.5).astype('int32')\n",
        "\n",
        "results = pd.DataFrame({\n",
        "    'predicted_label': y_pred_labels.flatten(),\n",
        "    'actual_label': y_test.flatten()\n",
        "})\n",
        "\n",
        "print(results.head())\n",
        "\n",
        "print(classification_report(y_test, y_pred_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9gKEtPYRb2_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a5310e5-7eea-4c28-acf1-9f96d7b23706"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 90 Complete [00h 00m 19s]\n",
            "val_mae: 0.49293482303619385\n",
            "\n",
            "Best val_mae So Far: 0.484881728887558\n",
            "Total elapsed time: 00h 21m 34s\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2493 - mae: 0.4679  \n",
            "Model 1: Test MAE = 0.4770, Loss (MSE) = 0.2586\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Model 1: R² = -0.0477\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2617 - mae: 0.4864\n",
            "Model 2: Test MAE = 0.4930, Loss (MSE) = 0.2696\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
            "Model 2: R² = -0.0922\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2479 - mae: 0.4733\n",
            "Model 3: Test MAE = 0.4795, Loss (MSE) = 0.2532\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Model 3: R² = -0.0258\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.2469 - mae: 0.4732\n",
            "Model 4: Test MAE = 0.4798, Loss (MSE) = 0.2534\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Model 4: R² = -0.0264\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2526 - mae: 0.4728  \n",
            "Model 5: Test MAE = 0.4805, Loss (MSE) = 0.2604\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Model 5: R² = -0.0547\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2545 - mae: 0.4883  \n",
            "Model 6: Test MAE = 0.4904, Loss (MSE) = 0.2572\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Model 6: R² = -0.0418\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2551 - mae: 0.4854  \n",
            "Model 7: Test MAE = 0.4905, Loss (MSE) = 0.2599\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Model 7: R² = -0.0527\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2523 - mae: 0.4871  \n",
            "Model 8: Test MAE = 0.4898, Loss (MSE) = 0.2553\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Model 8: R² = -0.0344\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2529 - mae: 0.4813  \n",
            "Model 9: Test MAE = 0.4864, Loss (MSE) = 0.2586\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Model 9: R² = -0.0475\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2479 - mae: 0.4878  \n",
            "Model 10: Test MAE = 0.4903, Loss (MSE) = 0.2508\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Model 10: R² = -0.0160\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2440 - mae: 0.4794  \n",
            "Model 11: Test MAE = 0.4855, Loss (MSE) = 0.2505\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Model 11: R² = -0.0148\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2544 - mae: 0.4902\n",
            "Model 12: Test MAE = 0.4919, Loss (MSE) = 0.2569\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Model 12: R² = -0.0407\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2577 - mae: 0.4922  \n",
            "Model 13: Test MAE = 0.4976, Loss (MSE) = 0.2630\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Model 13: R² = -0.0655\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2440 - mae: 0.4770  \n",
            "Model 14: Test MAE = 0.4805, Loss (MSE) = 0.2474\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Model 14: R² = -0.0024\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2482 - mae: 0.4784\n",
            "Model 15: Test MAE = 0.4848, Loss (MSE) = 0.2537\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Model 15: R² = -0.0278\n"
          ]
        }
      ],
      "source": [
        "#Hyperparameter tuning for cosine/MNLI\n",
        "#regression\n",
        "y_regression = y.astype('float32')\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train_scaled, X_temp, y_train, y_temp = train_test_split(X_scaled, y_regression, test_size=0.2, random_state=42)\n",
        "X_val_scaled, X_test_scaled, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(\n",
        "        hp.Int('units_input', min_value=64, max_value=256, step=64),\n",
        "        activation=hp.Choice('activation_input', ['relu', 'tanh']),\n",
        "        input_shape=(X.shape[1],)\n",
        "    ))\n",
        "\n",
        "    for i in range(hp.Int('num_layers', 1, 3)):\n",
        "        model.add(Dense(\n",
        "            units=hp.Int(f'units_{i}', min_value=64, max_value=512, step=64),\n",
        "            activation=hp.Choice(f'activation_{i}', ['relu', 'tanh'])\n",
        "        ))\n",
        "        if hp.Boolean(f'dropout_{i}'):\n",
        "            model.add(Dropout(rate=hp.Float(f'dropout_rate_{i}', min_value=0.1, max_value=0.5, step=0.1)))\n",
        "\n",
        "    model.add(Dense(1, activation='linear'))\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(\n",
        "            learning_rate=hp.Float('lr', 1e-5, 1e-3, sampling='log')),\n",
        "        loss='mean_squared_error',\n",
        "        metrics=['mae']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "tuner = kt.Hyperband(\n",
        "    build_model,\n",
        "    objective='val_mae',\n",
        "    max_epochs=30,\n",
        "    factor=3,\n",
        "    directory='hyperband_dir',\n",
        "    project_name='tlt_direction_regression'\n",
        ")\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "tuner.search(\n",
        "    X_train_scaled, y_train,\n",
        "    epochs=50,\n",
        "    validation_data=(X_val_scaled, y_val),\n",
        "    callbacks=[early_stopping],\n",
        "    batch_size=64\n",
        ")\n",
        "\n",
        "best_models = tuner.get_best_models(num_models=15)\n",
        "\n",
        "for idx, model in enumerate(best_models):\n",
        "    test_loss, test_mae = model.evaluate(X_test_scaled, y_test, verbose=1)\n",
        "    print(f\"Model {idx+1}: Test MAE = {test_mae:.4f}, Loss (MSE) = {test_loss:.4f}\")\n",
        "    y_pred = model.predict(X_test_scaled).flatten()\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    print(f\"Model {idx+1}: R² = {r2:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5p4mT1vmRh6_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a97cba5-fdd2-4953-d175-423def6d18a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model 1 Evaluation:\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.4286    0.0773    0.1310       194\n",
            "           1     0.5547    0.9177    0.6915       243\n",
            "\n",
            "    accuracy                         0.5446       437\n",
            "   macro avg     0.4916    0.4975    0.4112       437\n",
            "weighted avg     0.4987    0.5446    0.4427       437\n",
            "\n",
            "\n",
            "Model 2 Evaluation:\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.4524    0.0979    0.1610       194\n",
            "           1     0.5570    0.9053    0.6897       243\n",
            "\n",
            "    accuracy                         0.5469       437\n",
            "   macro avg     0.5047    0.5016    0.4253       437\n",
            "weighted avg     0.5105    0.5469    0.4550       437\n",
            "\n",
            "\n",
            "Model 3 Evaluation:\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.4634    0.0979    0.1617       194\n",
            "           1     0.5581    0.9095    0.6917       243\n",
            "\n",
            "    accuracy                         0.5492       437\n",
            "   macro avg     0.5107    0.5037    0.4267       437\n",
            "weighted avg     0.5161    0.5492    0.4564       437\n",
            "\n",
            "\n",
            "Model 4 Evaluation:\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.5000    0.1082    0.1780       194\n",
            "           1     0.5620    0.9136    0.6959       243\n",
            "\n",
            "    accuracy                         0.5561       437\n",
            "   macro avg     0.5310    0.5109    0.4369       437\n",
            "weighted avg     0.5345    0.5561    0.4660       437\n",
            "\n",
            "\n",
            "Model 5 Evaluation:\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.4688    0.0773    0.1327       194\n",
            "           1     0.5580    0.9300    0.6975       243\n",
            "\n",
            "    accuracy                         0.5515       437\n",
            "   macro avg     0.5134    0.5037    0.4151       437\n",
            "weighted avg     0.5184    0.5515    0.4468       437\n",
            "\n",
            "\n",
            "Model 6 Evaluation:\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.5000    0.0619    0.1101       194\n",
            "           1     0.5593    0.9506    0.7043       243\n",
            "\n",
            "    accuracy                         0.5561       437\n",
            "   macro avg     0.5297    0.5062    0.4072       437\n",
            "weighted avg     0.5330    0.5561    0.4405       437\n",
            "\n",
            "\n",
            "Model 7 Evaluation:\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.4898    0.1237    0.1975       194\n",
            "           1     0.5619    0.8971    0.6910       243\n",
            "\n",
            "    accuracy                         0.5538       437\n",
            "   macro avg     0.5258    0.5104    0.4442       437\n",
            "weighted avg     0.5299    0.5538    0.4719       437\n",
            "\n",
            "\n",
            "Model 8 Evaluation:\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.4062    0.1340    0.2016       194\n",
            "           1     0.5496    0.8436    0.6656       243\n",
            "\n",
            "    accuracy                         0.5286       437\n",
            "   macro avg     0.4779    0.4888    0.4336       437\n",
            "weighted avg     0.4860    0.5286    0.4596       437\n",
            "\n",
            "\n",
            "Model 9 Evaluation:\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.5000    0.1082    0.1780       194\n",
            "           1     0.5620    0.9136    0.6959       243\n",
            "\n",
            "    accuracy                         0.5561       437\n",
            "   macro avg     0.5310    0.5109    0.4369       437\n",
            "weighted avg     0.5345    0.5561    0.4660       437\n",
            "\n",
            "\n",
            "Model 10 Evaluation:\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.5556    0.0773    0.1357       194\n",
            "           1     0.5634    0.9506    0.7075       243\n",
            "\n",
            "    accuracy                         0.5629       437\n",
            "   macro avg     0.5595    0.5140    0.4216       437\n",
            "weighted avg     0.5599    0.5629    0.4537       437\n",
            "\n",
            "\n",
            "Model 11 Evaluation:\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.5333    0.0412    0.0766       194\n",
            "           1     0.5592    0.9712    0.7098       243\n",
            "\n",
            "    accuracy                         0.5584       437\n",
            "   macro avg     0.5463    0.5062    0.3932       437\n",
            "weighted avg     0.5477    0.5584    0.4287       437\n",
            "\n",
            "\n",
            "Model 12 Evaluation:\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.3896    0.1546    0.2214       194\n",
            "           1     0.5444    0.8066    0.6501       243\n",
            "\n",
            "    accuracy                         0.5172       437\n",
            "   macro avg     0.4670    0.4806    0.4357       437\n",
            "weighted avg     0.4757    0.5172    0.4598       437\n",
            "\n",
            "\n",
            "Model 13 Evaluation:\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.3962    0.1082    0.1700       194\n",
            "           1     0.5495    0.8683    0.6730       243\n",
            "\n",
            "    accuracy                         0.5309       437\n",
            "   macro avg     0.4729    0.4883    0.4215       437\n",
            "weighted avg     0.4814    0.5309    0.4497       437\n",
            "\n",
            "\n",
            "Model 14 Evaluation:\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.5000    0.0876    0.1491       194\n",
            "           1     0.5608    0.9300    0.6997       243\n",
            "\n",
            "    accuracy                         0.5561       437\n",
            "   macro avg     0.5304    0.5088    0.4244       437\n",
            "weighted avg     0.5338    0.5561    0.4553       437\n",
            "\n",
            "\n",
            "Model 15 Evaluation:\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.5429    0.0979    0.1659       194\n",
            "           1     0.5647    0.9342    0.7039       243\n",
            "\n",
            "    accuracy                         0.5629       437\n",
            "   macro avg     0.5538    0.5160    0.4349       437\n",
            "weighted avg     0.5550    0.5629    0.4651       437\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Hyperparameter tuning for cosine/MNLI\n",
        "#classification\n",
        "\n",
        "def binary_focal_loss(gamma=2.0, alpha=0.25):\n",
        "    def loss(y_true, y_pred):\n",
        "        y_true = tf.cast(y_true, tf.float32)\n",
        "        epsilon = K.epsilon()\n",
        "        y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
        "\n",
        "        p_t = tf.where(tf.equal(y_true, 1), y_pred, 1 - y_pred)\n",
        "        alpha_t = tf.where(tf.equal(y_true, 1), alpha, 1 - alpha)\n",
        "        focal_loss = -alpha_t * K.pow(1. - p_t, gamma) * K.log(p_t)\n",
        "        return K.mean(focal_loss)\n",
        "    return loss\n",
        "\n",
        "\n",
        "y_binary = (y > 0).astype(int)\n",
        "y_train_flat = y_train.ravel()  # or use .flatten()\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train_scaled, X_temp, y_train, y_temp = train_test_split(X_scaled, y_binary, test_size=0.2, random_state=42)\n",
        "X_val_scaled, X_test_scaled, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "classes = np.unique(y_train)\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train_flat), y=y_train_flat)\n",
        "class_weight_dict = dict(zip(np.unique(y_train_flat), class_weights))\n",
        "\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(\n",
        "        hp.Int('units_input', min_value=64, max_value=256, step=64),\n",
        "        activation=hp.Choice('activation_input', ['relu', 'tanh']),\n",
        "        input_shape=(X.shape[1],)\n",
        "    ))\n",
        "\n",
        "    for i in range(hp.Int('num_layers', 1, 3)):\n",
        "        model.add(Dense(\n",
        "            units=hp.Int(f'units_{i}', min_value=64, max_value=512, step=64),\n",
        "            activation=hp.Choice(f'activation_{i}', ['relu', 'tanh'])\n",
        "        ))\n",
        "        if hp.Boolean(f'dropout_{i}'):\n",
        "            model.add(Dropout(rate=hp.Float(f'dropout_rate_{i}', min_value=0.1, max_value=0.5, step=0.1)))\n",
        "\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(\n",
        "        learning_rate=hp.Float('lr', 1e-5, 1e-3, sampling='log')),\n",
        "    loss=binary_focal_loss(gamma=2.0, alpha=0.25),\n",
        "    metrics=[\n",
        "        tf.keras.metrics.BinaryAccuracy(name=\"accuracy\"),\n",
        "        tf.keras.metrics.Precision(name=\"precision\"),\n",
        "        tf.keras.metrics.Recall(name=\"recall\")\n",
        "    ]\n",
        "    )\n",
        "\n",
        "\n",
        "    return model\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "tuner = kt.Hyperband(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_epochs=30,\n",
        "    factor=3,\n",
        "    directory='hyperband_dir',\n",
        "    project_name='tlt_direction_classification_focal'\n",
        ")\n",
        "\n",
        "tuner.search(\n",
        "    X_train_scaled, y_train,\n",
        "    epochs=50,\n",
        "    validation_data=(X_val_scaled, y_val),\n",
        "    callbacks=[early_stopping],\n",
        "    batch_size=64,\n",
        "    class_weight=class_weight_dict\n",
        ")\n",
        "\n",
        "best_models = tuner.get_best_models(num_models=15)\n",
        "\n",
        "for idx, model in enumerate(best_models):\n",
        "    y_pred_probs = model.predict(X_test_scaled)\n",
        "    y_pred = (y_pred_probs > 0.5).astype('int32')\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Model {idx+1}: Accuracy = {acc:.4f}\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Example trading bot\n",
        "\n",
        "money = 10000\n",
        "\n",
        "for index, row in results.iterrows():\n",
        "    prediction = row['predicted_change']\n",
        "    bet = prediction * money / 10\n",
        "    result = bet * (row['actual_change'] / 100.0)\n",
        "    money += result\n",
        "\n",
        "    print(f\"prediction: {prediction:.2f}, real: {row['actual_change']:.2f}%, result: {result:.3f}, money: {money:.3f}\")\n"
      ],
      "metadata": {
        "id": "Oaz0hfEIwNUL",
        "outputId": "846f9540-23dd-4431-9a56-8ac590b6e8f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prediction: 0.10, real: 0.36%, result: 0.376, money: 10000.376\n",
            "prediction: 0.05, real: 0.07%, result: 0.035, money: 10000.411\n",
            "prediction: 0.05, real: 0.45%, result: 0.201, money: 10000.612\n",
            "prediction: 0.05, real: 0.77%, result: 0.347, money: 10000.960\n",
            "prediction: 0.05, real: -1.92%, result: -0.865, money: 10000.095\n",
            "prediction: 0.05, real: 1.16%, result: 0.521, money: 10000.616\n",
            "prediction: 0.06, real: 0.09%, result: 0.054, money: 10000.670\n",
            "prediction: -0.08, real: 0.57%, result: -0.447, money: 10000.223\n",
            "prediction: -0.03, real: 0.13%, result: -0.037, money: 10000.186\n",
            "prediction: 0.05, real: -2.44%, result: -1.267, money: 9998.919\n",
            "prediction: 0.05, real: 0.05%, result: 0.023, money: 9998.942\n",
            "prediction: 0.02, real: -0.97%, result: -0.200, money: 9998.742\n",
            "prediction: 0.06, real: -0.73%, result: -0.470, money: 9998.272\n",
            "prediction: 0.10, real: 0.62%, result: 0.645, money: 9998.917\n",
            "prediction: 0.07, real: -0.73%, result: -0.502, money: 9998.415\n",
            "prediction: -0.69, real: 0.86%, result: -5.975, money: 9992.440\n",
            "prediction: 0.02, real: 1.15%, result: 0.244, money: 9992.684\n",
            "prediction: 0.07, real: 2.14%, result: 1.413, money: 9994.097\n",
            "prediction: 0.06, real: 0.20%, result: 0.111, money: 9994.208\n",
            "prediction: -0.11, real: -0.72%, result: 0.778, money: 9994.986\n",
            "prediction: 0.07, real: -1.06%, result: -0.699, money: 9994.287\n",
            "prediction: 0.06, real: 0.03%, result: 0.017, money: 9994.304\n",
            "prediction: -0.05, real: 0.77%, result: -0.417, money: 9993.887\n",
            "prediction: 0.03, real: 0.92%, result: 0.312, money: 9994.199\n",
            "prediction: 0.05, real: -0.42%, result: -0.225, money: 9993.975\n",
            "prediction: 0.05, real: 0.31%, result: 0.162, money: 9994.137\n",
            "prediction: 0.06, real: 0.16%, result: 0.092, money: 9994.229\n",
            "prediction: 0.04, real: 0.47%, result: 0.191, money: 9994.420\n",
            "prediction: 0.04, real: 0.56%, result: 0.246, money: 9994.666\n",
            "prediction: 0.06, real: -0.92%, result: -0.555, money: 9994.111\n",
            "prediction: 0.06, real: -0.22%, result: -0.140, money: 9993.971\n",
            "prediction: 0.05, real: 1.07%, result: 0.483, money: 9994.454\n",
            "prediction: -0.03, real: 0.06%, result: -0.016, money: 9994.437\n",
            "prediction: 0.05, real: -0.55%, result: -0.246, money: 9994.192\n",
            "prediction: 0.08, real: -0.69%, result: -0.560, money: 9993.631\n",
            "prediction: 0.05, real: -0.91%, result: -0.408, money: 9993.223\n",
            "prediction: 0.05, real: 0.65%, result: 0.303, money: 9993.526\n",
            "prediction: 0.08, real: -0.32%, result: -0.254, money: 9993.272\n",
            "prediction: 0.05, real: 0.57%, result: 0.256, money: 9993.528\n",
            "prediction: 0.05, real: -0.15%, result: -0.079, money: 9993.448\n",
            "prediction: 0.05, real: 0.12%, result: 0.052, money: 9993.500\n",
            "prediction: 0.05, real: 0.16%, result: 0.071, money: 9993.571\n",
            "prediction: -0.22, real: 0.69%, result: -1.506, money: 9992.065\n",
            "prediction: -1.25, real: -0.80%, result: 10.020, money: 10002.085\n",
            "prediction: -0.58, real: 0.11%, result: -0.662, money: 10001.422\n",
            "prediction: 0.02, real: 0.16%, result: 0.037, money: 10001.459\n",
            "prediction: 0.07, real: 5.84%, result: 4.038, money: 10005.498\n",
            "prediction: 0.05, real: 0.90%, result: 0.404, money: 10005.901\n",
            "prediction: 0.05, real: -0.24%, result: -0.110, money: 10005.791\n",
            "prediction: 0.05, real: -0.51%, result: -0.231, money: 10005.561\n",
            "prediction: 0.23, real: -2.51%, result: -5.861, money: 9999.699\n",
            "prediction: 0.07, real: 0.29%, result: 0.193, money: 9999.892\n",
            "prediction: 0.05, real: 1.24%, result: 0.558, money: 10000.450\n",
            "prediction: 0.08, real: 0.51%, result: 0.425, money: 10000.875\n",
            "prediction: 0.05, real: -0.85%, result: -0.384, money: 10000.491\n",
            "prediction: 0.07, real: -0.35%, result: -0.227, money: 10000.264\n",
            "prediction: 0.05, real: 2.64%, result: 1.356, money: 10001.620\n",
            "prediction: 0.09, real: -0.27%, result: -0.229, money: 10001.391\n",
            "prediction: 0.07, real: -0.02%, result: -0.012, money: 10001.379\n",
            "prediction: 0.09, real: 0.62%, result: 0.540, money: 10001.919\n",
            "prediction: 0.05, real: 1.85%, result: 0.855, money: 10002.775\n",
            "prediction: 0.05, real: 0.83%, result: 0.420, money: 10003.195\n",
            "prediction: 0.05, real: -0.79%, result: -0.354, money: 10002.840\n",
            "prediction: 0.08, real: 0.07%, result: 0.052, money: 10002.892\n",
            "prediction: 0.05, real: -0.64%, result: -0.341, money: 10002.552\n",
            "prediction: -0.00, real: -0.51%, result: 0.023, money: 10002.575\n",
            "prediction: 0.08, real: -0.06%, result: -0.047, money: 10002.527\n",
            "prediction: 0.06, real: -0.34%, result: -0.194, money: 10002.333\n",
            "prediction: 0.05, real: -0.35%, result: -0.184, money: 10002.149\n",
            "prediction: 0.05, real: 0.18%, result: 0.081, money: 10002.230\n",
            "prediction: 0.05, real: 0.57%, result: 0.258, money: 10002.488\n",
            "prediction: -0.08, real: 0.60%, result: -0.510, money: 10001.978\n",
            "prediction: 0.07, real: -0.05%, result: -0.037, money: 10001.941\n",
            "prediction: 0.05, real: 0.32%, result: 0.143, money: 10002.084\n",
            "prediction: 0.05, real: 0.04%, result: 0.016, money: 10002.101\n",
            "prediction: 0.05, real: -0.19%, result: -0.086, money: 10002.014\n",
            "prediction: 0.05, real: -1.59%, result: -0.716, money: 10001.299\n",
            "prediction: 0.05, real: 1.31%, result: 0.589, money: 10001.888\n",
            "prediction: 0.07, real: -0.04%, result: -0.027, money: 10001.861\n",
            "prediction: 0.05, real: 0.05%, result: 0.023, money: 10001.884\n",
            "prediction: 0.07, real: -0.01%, result: -0.010, money: 10001.873\n",
            "prediction: 0.05, real: 0.68%, result: 0.305, money: 10002.178\n",
            "prediction: -0.20, real: 0.41%, result: -0.819, money: 10001.359\n",
            "prediction: 0.06, real: 0.48%, result: 0.300, money: 10001.659\n",
            "prediction: -0.20, real: -0.73%, result: 1.464, money: 10003.123\n",
            "prediction: 0.07, real: 0.38%, result: 0.263, money: 10003.386\n",
            "prediction: 0.07, real: 0.91%, result: 0.627, money: 10004.013\n",
            "prediction: 0.08, real: 0.04%, result: 0.032, money: 10004.045\n",
            "prediction: 0.04, real: -3.42%, result: -1.536, money: 10002.509\n",
            "prediction: 0.05, real: 2.95%, result: 1.329, money: 10003.838\n",
            "prediction: 0.07, real: 0.46%, result: 0.319, money: 10004.157\n",
            "prediction: 0.05, real: 0.33%, result: 0.151, money: 10004.307\n",
            "prediction: 0.04, real: -0.06%, result: -0.027, money: 10004.280\n",
            "prediction: 0.07, real: 1.75%, result: 1.143, money: 10005.423\n",
            "prediction: 0.05, real: -1.20%, result: -0.540, money: 10004.884\n",
            "prediction: -0.16, real: 0.85%, result: -1.374, money: 10003.510\n",
            "prediction: -0.34, real: -2.49%, result: 8.530, money: 10012.040\n",
            "prediction: 0.05, real: 0.38%, result: 0.172, money: 10012.212\n",
            "prediction: 0.05, real: 1.24%, result: 0.559, money: 10012.771\n",
            "prediction: 0.05, real: -0.53%, result: -0.237, money: 10012.534\n",
            "prediction: 0.07, real: 0.10%, result: 0.069, money: 10012.604\n",
            "prediction: -0.05, real: 0.48%, result: -0.251, money: 10012.353\n",
            "prediction: 0.05, real: 0.99%, result: 0.445, money: 10012.798\n",
            "prediction: 0.07, real: -1.50%, result: -0.975, money: 10011.823\n",
            "prediction: 0.05, real: 0.80%, result: 0.363, money: 10012.186\n",
            "prediction: 0.04, real: 0.59%, result: 0.257, money: 10012.442\n",
            "prediction: 0.05, real: -0.29%, result: -0.131, money: 10012.312\n",
            "prediction: 0.05, real: -0.05%, result: -0.023, money: 10012.289\n",
            "prediction: 0.05, real: 0.09%, result: 0.050, money: 10012.339\n",
            "prediction: 0.05, real: -0.23%, result: -0.105, money: 10012.234\n",
            "prediction: 0.07, real: -0.55%, result: -0.390, money: 10011.844\n",
            "prediction: 0.05, real: 0.18%, result: 0.093, money: 10011.936\n",
            "prediction: 0.08, real: 0.63%, result: 0.523, money: 10012.459\n",
            "prediction: 0.05, real: -0.17%, result: -0.075, money: 10012.384\n",
            "prediction: 0.08, real: 2.00%, result: 1.512, money: 10013.896\n",
            "prediction: -0.04, real: -0.13%, result: 0.049, money: 10013.945\n",
            "prediction: 0.05, real: 0.90%, result: 0.404, money: 10014.348\n",
            "prediction: 0.05, real: 0.46%, result: 0.206, money: 10014.555\n",
            "prediction: 0.00, real: -0.09%, result: -0.001, money: 10014.553\n",
            "prediction: 0.03, real: 0.43%, result: 0.122, money: 10014.675\n",
            "prediction: 0.07, real: 0.28%, result: 0.184, money: 10014.859\n",
            "prediction: 0.00, real: -0.61%, result: -0.015, money: 10014.843\n",
            "prediction: 0.05, real: -3.04%, result: -1.370, money: 10013.474\n",
            "prediction: -0.04, real: 0.24%, result: -0.094, money: 10013.380\n",
            "prediction: 0.05, real: 0.64%, result: 0.289, money: 10013.669\n",
            "prediction: 0.05, real: 0.63%, result: 0.285, money: 10013.954\n",
            "prediction: 0.07, real: 0.03%, result: 0.019, money: 10013.973\n",
            "prediction: 0.06, real: -1.94%, result: -1.178, money: 10012.795\n",
            "prediction: -0.40, real: -1.99%, result: 8.037, money: 10020.832\n",
            "prediction: 0.05, real: 0.81%, result: 0.367, money: 10021.199\n",
            "prediction: 0.05, real: 0.89%, result: 0.400, money: 10021.599\n",
            "prediction: 0.06, real: -0.17%, result: -0.101, money: 10021.498\n",
            "prediction: 0.08, real: 0.91%, result: 0.698, money: 10022.196\n",
            "prediction: 0.09, real: 0.05%, result: 0.043, money: 10022.239\n",
            "prediction: 0.05, real: 1.40%, result: 0.632, money: 10022.871\n",
            "prediction: 0.27, real: 0.07%, result: 0.193, money: 10023.064\n",
            "prediction: 0.07, real: 0.24%, result: 0.184, money: 10023.248\n",
            "prediction: 0.05, real: 0.50%, result: 0.232, money: 10023.479\n",
            "prediction: 0.06, real: 0.16%, result: 0.090, money: 10023.569\n",
            "prediction: 0.04, real: -0.29%, result: -0.127, money: 10023.442\n",
            "prediction: 0.05, real: -1.95%, result: -0.878, money: 10022.564\n",
            "prediction: 0.07, real: -0.76%, result: -0.571, money: 10021.993\n",
            "prediction: 0.05, real: -0.08%, result: -0.038, money: 10021.955\n",
            "prediction: 0.05, real: -0.28%, result: -0.125, money: 10021.830\n",
            "prediction: 0.05, real: -0.73%, result: -0.330, money: 10021.500\n",
            "prediction: 0.06, real: -0.71%, result: -0.447, money: 10021.053\n",
            "prediction: 0.05, real: -0.71%, result: -0.376, money: 10020.676\n",
            "prediction: 0.05, real: 0.64%, result: 0.289, money: 10020.966\n",
            "prediction: 0.07, real: 0.48%, result: 0.353, money: 10021.318\n",
            "prediction: 0.09, real: -0.05%, result: -0.051, money: 10021.267\n",
            "prediction: 0.06, real: -0.25%, result: -0.158, money: 10021.109\n",
            "prediction: 0.05, real: 0.59%, result: 0.265, money: 10021.374\n",
            "prediction: 0.05, real: 0.25%, result: 0.112, money: 10021.485\n",
            "prediction: 0.05, real: -0.45%, result: -0.203, money: 10021.283\n",
            "prediction: -0.65, real: 0.51%, result: -3.271, money: 10018.011\n",
            "prediction: 0.05, real: -0.83%, result: -0.402, money: 10017.609\n",
            "prediction: -0.00, real: 0.09%, result: -0.004, money: 10017.605\n",
            "prediction: -0.04, real: 0.99%, result: -0.442, money: 10017.163\n",
            "prediction: 0.07, real: 0.98%, result: 0.652, money: 10017.814\n",
            "prediction: -0.06, real: -1.60%, result: 0.943, money: 10018.757\n",
            "prediction: 0.05, real: -0.02%, result: -0.011, money: 10018.747\n",
            "prediction: 0.05, real: -1.41%, result: -0.637, money: 10018.110\n",
            "prediction: 0.05, real: -1.44%, result: -0.649, money: 10017.461\n",
            "prediction: 0.05, real: -0.26%, result: -0.117, money: 10017.344\n",
            "prediction: 0.04, real: 0.73%, result: 0.326, money: 10017.670\n",
            "prediction: 0.05, real: -3.38%, result: -1.527, money: 10016.143\n",
            "prediction: 0.05, real: -1.56%, result: -0.706, money: 10015.437\n",
            "prediction: 0.11, real: -0.01%, result: -0.015, money: 10015.422\n",
            "prediction: -0.02, real: 1.08%, result: -0.229, money: 10015.193\n",
            "prediction: -0.58, real: -1.40%, result: 8.182, money: 10023.375\n",
            "prediction: 0.05, real: 0.41%, result: 0.186, money: 10023.561\n",
            "prediction: 0.05, real: -1.05%, result: -0.473, money: 10023.088\n",
            "prediction: 0.11, real: 0.56%, result: 0.639, money: 10023.727\n",
            "prediction: 0.05, real: 0.03%, result: 0.015, money: 10023.743\n",
            "prediction: 0.17, real: -0.18%, result: -0.297, money: 10023.446\n",
            "prediction: 0.06, real: -0.31%, result: -0.198, money: 10023.248\n",
            "prediction: 0.05, real: 0.19%, result: 0.100, money: 10023.348\n",
            "prediction: -0.07, real: -0.85%, result: 0.619, money: 10023.967\n",
            "prediction: 0.08, real: 0.60%, result: 0.506, money: 10024.472\n",
            "prediction: 0.07, real: -0.40%, result: -0.292, money: 10024.180\n",
            "prediction: 0.05, real: 0.17%, result: 0.077, money: 10024.257\n",
            "prediction: -0.08, real: 1.11%, result: -0.876, money: 10023.381\n",
            "prediction: 0.05, real: 0.37%, result: 0.166, money: 10023.546\n",
            "prediction: -1.51, real: -9.57%, result: 144.942, money: 10168.488\n",
            "prediction: 0.05, real: -0.73%, result: -0.333, money: 10168.156\n",
            "prediction: 0.05, real: -0.04%, result: -0.020, money: 10168.135\n",
            "prediction: 0.03, real: 1.19%, result: 0.372, money: 10168.507\n",
            "prediction: 0.05, real: -0.17%, result: -0.080, money: 10168.427\n",
            "prediction: -0.02, real: 0.98%, result: -0.209, money: 10168.218\n",
            "prediction: 0.05, real: 0.17%, result: 0.079, money: 10168.297\n",
            "prediction: 0.04, real: -0.51%, result: -0.232, money: 10168.065\n",
            "prediction: 0.05, real: 0.17%, result: 0.079, money: 10168.144\n",
            "prediction: 0.08, real: -1.05%, result: -0.837, money: 10167.307\n",
            "prediction: 0.04, real: 0.12%, result: 0.053, money: 10167.360\n",
            "prediction: 0.07, real: 0.01%, result: 0.007, money: 10167.367\n",
            "prediction: 0.07, real: 0.34%, result: 0.248, money: 10167.616\n",
            "prediction: 0.05, real: 0.07%, result: 0.032, money: 10167.647\n",
            "prediction: 0.05, real: -1.35%, result: -0.619, money: 10167.029\n",
            "prediction: -0.03, real: 0.54%, result: -0.155, money: 10166.873\n",
            "prediction: 0.05, real: 0.18%, result: 0.084, money: 10166.957\n",
            "prediction: 0.05, real: 0.52%, result: 0.236, money: 10167.193\n",
            "prediction: 0.06, real: -0.27%, result: -0.171, money: 10167.022\n",
            "prediction: 0.06, real: 0.10%, result: 0.064, money: 10167.086\n",
            "prediction: 0.04, real: 0.05%, result: 0.022, money: 10167.108\n",
            "prediction: 0.05, real: 0.04%, result: 0.017, money: 10167.125\n",
            "prediction: 0.05, real: -0.82%, result: -0.375, money: 10166.750\n",
            "prediction: -2.34, real: -3.17%, result: 75.278, money: 10242.027\n",
            "prediction: 0.05, real: -0.14%, result: -0.072, money: 10241.955\n",
            "prediction: 0.05, real: 0.48%, result: 0.220, money: 10242.176\n",
            "prediction: 0.07, real: -0.35%, result: -0.254, money: 10241.922\n",
            "prediction: 0.26, real: -0.80%, result: -2.109, money: 10239.813\n",
            "prediction: -0.05, real: 2.64%, result: -1.442, money: 10238.372\n",
            "prediction: 0.05, real: -1.09%, result: -0.504, money: 10237.868\n",
            "prediction: 0.08, real: 3.25%, result: 2.504, money: 10240.372\n",
            "prediction: 0.11, real: 0.75%, result: 0.866, money: 10241.238\n",
            "prediction: 0.06, real: -0.12%, result: -0.073, money: 10241.165\n",
            "prediction: 0.04, real: -2.50%, result: -1.142, money: 10240.023\n",
            "prediction: 0.01, real: 0.48%, result: 0.045, money: 10240.068\n",
            "prediction: -0.18, real: 2.06%, result: -3.782, money: 10236.285\n",
            "prediction: 0.05, real: -0.62%, result: -0.286, money: 10235.999\n",
            "prediction: 0.10, real: -0.02%, result: -0.024, money: 10235.974\n",
            "prediction: 0.05, real: 0.58%, result: 0.268, money: 10236.243\n",
            "prediction: 0.05, real: -3.17%, result: -1.460, money: 10234.783\n",
            "prediction: 0.06, real: 0.28%, result: 0.188, money: 10234.971\n",
            "prediction: -0.14, real: -0.30%, result: 0.409, money: 10235.380\n",
            "prediction: 0.05, real: 0.30%, result: 0.138, money: 10235.518\n",
            "prediction: 0.05, real: 0.21%, result: 0.099, money: 10235.617\n",
            "prediction: 0.04, real: 0.93%, result: 0.421, money: 10236.038\n",
            "prediction: 0.05, real: -0.68%, result: -0.323, money: 10235.716\n",
            "prediction: 0.06, real: -0.54%, result: -0.308, money: 10235.407\n",
            "prediction: 0.05, real: -0.33%, result: -0.152, money: 10235.255\n",
            "prediction: 0.06, real: 0.53%, result: 0.336, money: 10235.592\n",
            "prediction: 0.05, real: 1.07%, result: 0.493, money: 10236.085\n",
            "prediction: 0.03, real: 2.22%, result: 0.608, money: 10236.693\n",
            "prediction: 0.05, real: 0.74%, result: 0.375, money: 10237.068\n",
            "prediction: 0.06, real: -1.81%, result: -1.154, money: 10235.914\n",
            "prediction: 0.05, real: 0.72%, result: 0.334, money: 10236.248\n",
            "prediction: 0.07, real: 0.72%, result: 0.541, money: 10236.789\n",
            "prediction: 0.05, real: 0.39%, result: 0.182, money: 10236.971\n",
            "prediction: 0.05, real: 0.05%, result: 0.023, money: 10236.994\n",
            "prediction: 0.05, real: -0.53%, result: -0.274, money: 10236.720\n",
            "prediction: 0.08, real: 0.68%, result: 0.551, money: 10237.271\n",
            "prediction: 0.05, real: -1.50%, result: -0.690, money: 10236.580\n",
            "prediction: 0.12, real: 0.95%, result: 1.160, money: 10237.740\n",
            "prediction: 0.08, real: 0.52%, result: 0.434, money: 10238.174\n",
            "prediction: -0.22, real: 1.69%, result: -3.748, money: 10234.426\n",
            "prediction: 0.10, real: -0.44%, result: -0.439, money: 10233.987\n",
            "prediction: 0.05, real: 0.80%, result: 0.368, money: 10234.355\n",
            "prediction: 0.05, real: -3.32%, result: -1.532, money: 10232.823\n",
            "prediction: -0.06, real: -0.20%, result: 0.121, money: 10232.944\n",
            "prediction: 0.05, real: -0.19%, result: -0.087, money: 10232.857\n",
            "prediction: 0.01, real: 0.44%, result: 0.044, money: 10232.902\n",
            "prediction: 0.06, real: -0.01%, result: -0.004, money: 10232.897\n",
            "prediction: 0.05, real: 0.38%, result: 0.177, money: 10233.074\n",
            "prediction: 0.05, real: 0.52%, result: 0.241, money: 10233.315\n",
            "prediction: 0.06, real: 0.04%, result: 0.023, money: 10233.338\n",
            "prediction: 0.05, real: 0.00%, result: 0.000, money: 10233.338\n",
            "prediction: 0.05, real: 1.23%, result: 0.583, money: 10233.921\n",
            "prediction: 0.02, real: 0.90%, result: 0.198, money: 10234.119\n",
            "prediction: 0.05, real: 0.29%, result: 0.134, money: 10234.253\n",
            "prediction: -0.15, real: 0.77%, result: -1.145, money: 10233.107\n",
            "prediction: 0.05, real: -1.80%, result: -0.831, money: 10232.277\n",
            "prediction: 0.05, real: -0.75%, result: -0.347, money: 10231.930\n",
            "prediction: 0.07, real: 2.30%, result: 1.752, money: 10233.682\n",
            "prediction: 0.05, real: 1.30%, result: 0.601, money: 10234.283\n",
            "prediction: 0.05, real: 0.74%, result: 0.342, money: 10234.625\n",
            "prediction: -0.12, real: -0.30%, result: 0.362, money: 10234.987\n",
            "prediction: 0.00, real: -0.28%, result: -0.008, money: 10234.980\n",
            "prediction: 0.04, real: 0.82%, result: 0.374, money: 10235.354\n",
            "prediction: 0.05, real: 0.36%, result: 0.165, money: 10235.519\n",
            "prediction: 0.05, real: 8.55%, result: 3.941, money: 10239.460\n",
            "prediction: 0.05, real: 0.41%, result: 0.191, money: 10239.651\n",
            "prediction: -0.49, real: 0.46%, result: -2.321, money: 10237.330\n",
            "prediction: 0.05, real: 1.61%, result: 0.744, money: 10238.074\n",
            "prediction: 0.07, real: 1.45%, result: 1.093, money: 10239.167\n",
            "prediction: 0.05, real: 0.16%, result: 0.072, money: 10239.239\n",
            "prediction: -0.07, real: 0.16%, result: -0.116, money: 10239.124\n",
            "prediction: -0.04, real: -1.69%, result: 0.734, money: 10239.857\n",
            "prediction: 0.05, real: 1.12%, result: 0.519, money: 10240.376\n",
            "prediction: 0.05, real: 0.37%, result: 0.171, money: 10240.547\n",
            "prediction: 0.05, real: 0.40%, result: 0.186, money: 10240.734\n",
            "prediction: 0.06, real: 0.23%, result: 0.131, money: 10240.865\n",
            "prediction: 0.05, real: -1.01%, result: -0.465, money: 10240.401\n",
            "prediction: 0.05, real: -0.35%, result: -0.160, money: 10240.241\n",
            "prediction: 0.05, real: 1.84%, result: 0.863, money: 10241.105\n",
            "prediction: 0.02, real: -0.38%, result: -0.091, money: 10241.014\n",
            "prediction: 0.05, real: -0.00%, result: -0.002, money: 10241.012\n",
            "prediction: 0.05, real: -1.07%, result: -0.493, money: 10240.519\n",
            "prediction: -0.03, real: 0.67%, result: -0.200, money: 10240.319\n",
            "prediction: 0.06, real: -1.36%, result: -0.882, money: 10239.436\n",
            "prediction: 0.08, real: 0.62%, result: 0.498, money: 10239.934\n",
            "prediction: 0.05, real: 1.36%, result: 0.629, money: 10240.563\n",
            "prediction: 0.11, real: 0.19%, result: 0.211, money: 10240.774\n",
            "prediction: 0.01, real: 0.51%, result: 0.056, money: 10240.829\n",
            "prediction: 0.07, real: -2.36%, result: -1.662, money: 10239.167\n",
            "prediction: 0.05, real: -1.26%, result: -0.582, money: 10238.585\n",
            "prediction: 0.05, real: 2.42%, result: 1.118, money: 10239.703\n",
            "prediction: -0.01, real: 0.20%, result: -0.022, money: 10239.681\n",
            "prediction: 0.07, real: -0.69%, result: -0.495, money: 10239.186\n",
            "prediction: 0.04, real: -0.35%, result: -0.161, money: 10239.025\n",
            "prediction: 0.05, real: -0.09%, result: -0.041, money: 10238.984\n",
            "prediction: 0.06, real: 0.70%, result: 0.409, money: 10239.393\n",
            "prediction: 0.05, real: -0.53%, result: -0.246, money: 10239.147\n",
            "prediction: 0.05, real: 0.42%, result: 0.192, money: 10239.339\n",
            "prediction: 0.05, real: 0.23%, result: 0.106, money: 10239.444\n",
            "prediction: 0.04, real: 1.07%, result: 0.488, money: 10239.932\n",
            "prediction: 0.05, real: 0.59%, result: 0.274, money: 10240.206\n",
            "prediction: 0.08, real: 0.95%, result: 0.739, money: 10240.945\n",
            "prediction: 0.04, real: -0.76%, result: -0.345, money: 10240.600\n",
            "prediction: 0.05, real: -0.22%, result: -0.101, money: 10240.500\n",
            "prediction: 0.07, real: -0.23%, result: -0.176, money: 10240.324\n",
            "prediction: 0.05, real: -1.63%, result: -0.753, money: 10239.571\n",
            "prediction: -1.74, real: 0.83%, result: -14.706, money: 10224.865\n",
            "prediction: 0.09, real: 5.40%, result: 4.856, money: 10229.721\n",
            "prediction: 0.07, real: -0.57%, result: -0.435, money: 10229.286\n",
            "prediction: 0.05, real: 0.29%, result: 0.136, money: 10229.422\n",
            "prediction: 0.07, real: -0.18%, result: -0.132, money: 10229.289\n",
            "prediction: 0.05, real: 0.13%, result: 0.058, money: 10229.348\n",
            "prediction: 0.05, real: 0.70%, result: 0.323, money: 10229.671\n",
            "prediction: -0.80, real: 0.56%, result: -4.586, money: 10225.085\n",
            "prediction: 0.05, real: 0.08%, result: 0.037, money: 10225.121\n",
            "prediction: -0.09, real: -0.54%, result: 0.499, money: 10225.621\n",
            "prediction: 0.05, real: -0.25%, result: -0.117, money: 10225.504\n",
            "prediction: 0.05, real: -0.26%, result: -0.118, money: 10225.386\n",
            "prediction: 0.05, real: -1.03%, result: -0.475, money: 10224.911\n",
            "prediction: 0.05, real: 0.30%, result: 0.136, money: 10225.047\n",
            "prediction: 0.06, real: 1.96%, result: 1.107, money: 10226.155\n",
            "prediction: 0.06, real: -0.02%, result: -0.012, money: 10226.143\n",
            "prediction: -0.11, real: -0.03%, result: 0.035, money: 10226.178\n",
            "prediction: 0.06, real: 0.11%, result: 0.069, money: 10226.247\n",
            "prediction: -0.01, real: -0.04%, result: 0.005, money: 10226.252\n",
            "prediction: 0.05, real: 0.33%, result: 0.151, money: 10226.403\n",
            "prediction: 0.05, real: -2.28%, result: -1.050, money: 10225.354\n",
            "prediction: 0.10, real: -0.55%, result: -0.580, money: 10224.773\n",
            "prediction: -2.89, real: -0.68%, result: 20.016, money: 10244.790\n",
            "prediction: 0.05, real: -0.19%, result: -0.086, money: 10244.704\n",
            "prediction: -0.12, real: 0.70%, result: -0.831, money: 10243.872\n",
            "prediction: 0.05, real: 3.98%, result: 2.075, money: 10245.947\n",
            "prediction: 0.05, real: 0.90%, result: 0.449, money: 10246.396\n",
            "prediction: 0.06, real: 0.07%, result: 0.043, money: 10246.439\n",
            "prediction: 0.04, real: 0.51%, result: 0.230, money: 10246.669\n",
            "prediction: 0.05, real: 0.98%, result: 0.474, money: 10247.143\n",
            "prediction: 0.05, real: 0.20%, result: 0.092, money: 10247.234\n",
            "prediction: -0.11, real: -0.10%, result: 0.112, money: 10247.346\n",
            "prediction: 0.07, real: 0.25%, result: 0.173, money: 10247.519\n",
            "prediction: 0.05, real: 0.46%, result: 0.212, money: 10247.731\n",
            "prediction: 0.05, real: 1.16%, result: 0.602, money: 10248.333\n",
            "prediction: 0.05, real: -0.09%, result: -0.041, money: 10248.292\n",
            "prediction: 0.06, real: -0.09%, result: -0.058, money: 10248.234\n",
            "prediction: 0.06, real: -0.05%, result: -0.031, money: 10248.203\n",
            "prediction: 0.05, real: -0.12%, result: -0.053, money: 10248.150\n",
            "prediction: 0.05, real: -0.47%, result: -0.219, money: 10247.931\n",
            "prediction: 0.07, real: -1.63%, result: -1.110, money: 10246.821\n",
            "prediction: -0.08, real: -1.25%, result: 1.057, money: 10247.878\n",
            "prediction: 0.05, real: 0.13%, result: 0.062, money: 10247.940\n",
            "prediction: 0.05, real: -0.65%, result: -0.298, money: 10247.641\n",
            "prediction: 0.06, real: -0.13%, result: -0.080, money: 10247.561\n",
            "prediction: 0.05, real: -0.26%, result: -0.118, money: 10247.443\n",
            "prediction: 0.11, real: -0.16%, result: -0.191, money: 10247.253\n",
            "prediction: 0.07, real: 0.15%, result: 0.109, money: 10247.362\n",
            "prediction: 0.05, real: -0.41%, result: -0.189, money: 10247.173\n",
            "prediction: 0.03, real: -1.52%, result: -0.522, money: 10246.651\n",
            "prediction: 0.05, real: -0.37%, result: -0.170, money: 10246.481\n",
            "prediction: 0.05, real: 1.90%, result: 0.879, money: 10247.360\n",
            "prediction: 0.07, real: 0.64%, result: 0.451, money: 10247.812\n",
            "prediction: 0.05, real: -2.38%, result: -1.146, money: 10246.666\n",
            "prediction: 0.05, real: 1.25%, result: 0.579, money: 10247.244\n",
            "prediction: 0.06, real: 0.19%, result: 0.117, money: 10247.362\n",
            "prediction: 0.05, real: 0.78%, result: 0.359, money: 10247.721\n",
            "prediction: 0.05, real: -1.20%, result: -0.552, money: 10247.169\n",
            "prediction: 0.12, real: 0.23%, result: 0.269, money: 10247.437\n",
            "prediction: -0.11, real: 0.85%, result: -0.939, money: 10246.499\n",
            "prediction: 0.06, real: -0.65%, result: -0.376, money: 10246.123\n",
            "prediction: -0.05, real: -1.52%, result: 0.740, money: 10246.863\n",
            "prediction: 0.09, real: 0.14%, result: 0.126, money: 10246.989\n",
            "prediction: 0.23, real: 0.06%, result: 0.147, money: 10247.137\n",
            "prediction: 0.07, real: -3.04%, result: -2.042, money: 10245.095\n",
            "prediction: 0.06, real: 0.26%, result: 0.167, money: 10245.262\n",
            "prediction: 0.08, real: 0.02%, result: 0.020, money: 10245.282\n",
            "prediction: 0.05, real: -0.02%, result: -0.009, money: 10245.273\n",
            "prediction: 0.05, real: 0.73%, result: 0.336, money: 10245.608\n",
            "prediction: 0.07, real: -3.04%, result: -2.321, money: 10243.288\n",
            "prediction: 0.05, real: -0.07%, result: -0.034, money: 10243.254\n",
            "prediction: 0.06, real: -1.28%, result: -0.757, money: 10242.497\n",
            "prediction: -0.29, real: 0.77%, result: -2.284, money: 10240.213\n",
            "prediction: 0.07, real: 1.96%, result: 1.324, money: 10241.538\n",
            "prediction: 0.05, real: 1.60%, result: 0.740, money: 10242.277\n",
            "prediction: 0.05, real: -0.31%, result: -0.141, money: 10242.136\n",
            "prediction: 0.04, real: -0.53%, result: -0.245, money: 10241.892\n",
            "prediction: 0.02, real: -0.47%, result: -0.074, money: 10241.818\n",
            "prediction: 0.06, real: 0.32%, result: 0.203, money: 10242.021\n",
            "prediction: 0.05, real: 0.18%, result: 0.097, money: 10242.118\n",
            "prediction: 0.05, real: 1.05%, result: 0.483, money: 10242.601\n",
            "prediction: 0.05, real: -1.09%, result: -0.504, money: 10242.097\n",
            "prediction: 0.05, real: 0.13%, result: 0.061, money: 10242.158\n",
            "prediction: 0.05, real: -1.26%, result: -0.580, money: 10241.578\n",
            "prediction: 0.06, real: -0.64%, result: -0.379, money: 10241.199\n",
            "prediction: 0.05, real: 0.05%, result: 0.022, money: 10241.221\n",
            "prediction: 0.01, real: 0.95%, result: 0.098, money: 10241.318\n",
            "prediction: 0.05, real: 1.31%, result: 0.605, money: 10241.923\n",
            "prediction: 0.05, real: -0.91%, result: -0.422, money: 10241.501\n",
            "prediction: 0.05, real: -0.09%, result: -0.041, money: 10241.461\n",
            "prediction: -0.12, real: 0.75%, result: -0.964, money: 10240.496\n",
            "prediction: 0.05, real: -0.34%, result: -0.155, money: 10240.342\n",
            "prediction: 0.10, real: 0.35%, result: 0.350, money: 10240.691\n",
            "prediction: 0.05, real: 0.07%, result: 0.033, money: 10240.724\n",
            "prediction: 0.05, real: -0.56%, result: -0.257, money: 10240.467\n",
            "prediction: 0.00, real: 1.05%, result: 0.052, money: 10240.519\n",
            "prediction: 0.15, real: -1.70%, result: -2.625, money: 10237.894\n",
            "prediction: 0.05, real: -0.51%, result: -0.236, money: 10237.658\n",
            "prediction: 0.11, real: 0.12%, result: 0.135, money: 10237.793\n",
            "prediction: -0.04, real: 1.87%, result: -0.803, money: 10236.990\n",
            "prediction: -0.02, real: -0.55%, result: 0.134, money: 10237.124\n",
            "prediction: 0.08, real: -0.37%, result: -0.284, money: 10236.840\n",
            "prediction: 0.04, real: -0.38%, result: -0.173, money: 10236.667\n",
            "prediction: 0.05, real: 1.10%, result: 0.507, money: 10237.174\n",
            "prediction: 0.08, real: -0.57%, result: -0.439, money: 10236.735\n",
            "prediction: 0.06, real: -0.91%, result: -0.543, money: 10236.192\n",
            "prediction: 0.07, real: -0.34%, result: -0.233, money: 10235.959\n",
            "prediction: 0.08, real: 0.12%, result: 0.104, money: 10236.063\n",
            "prediction: 0.05, real: -4.87%, result: -2.245, money: 10233.818\n",
            "prediction: -0.30, real: 1.32%, result: -4.096, money: 10229.722\n",
            "prediction: 0.05, real: -1.94%, result: -0.893, money: 10228.829\n",
            "prediction: 0.05, real: -1.38%, result: -0.759, money: 10228.069\n",
            "prediction: 0.05, real: -0.32%, result: -0.150, money: 10227.920\n",
            "prediction: 0.05, real: 0.67%, result: 0.308, money: 10228.228\n",
            "prediction: 0.04, real: 0.15%, result: 0.067, money: 10228.295\n",
            "prediction: 0.05, real: -0.63%, result: -0.292, money: 10228.003\n",
            "prediction: 0.08, real: 0.09%, result: 0.073, money: 10228.076\n",
            "prediction: 0.12, real: 0.55%, result: 0.664, money: 10228.740\n",
            "prediction: -0.06, real: 0.02%, result: -0.009, money: 10228.731\n",
            "prediction: 0.27, real: 2.64%, result: 7.165, money: 10235.896\n",
            "prediction: 0.05, real: 0.38%, result: 0.187, money: 10236.083\n",
            "prediction: 0.05, real: -1.30%, result: -0.707, money: 10235.376\n",
            "prediction: 0.05, real: -0.24%, result: -0.111, money: 10235.265\n",
            "prediction: 0.06, real: 1.00%, result: 0.585, money: 10235.850\n",
            "prediction: 0.07, real: 0.88%, result: 0.616, money: 10236.466\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
